{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "targets = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "predictions = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "report = classification_report(targets, predictions, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " '2': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " '3': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " '4': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " '5': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " '6': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " '7': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " '8': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " '9': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " 'accuracy': 1.0,\n",
       " 'macro avg': {'precision': 1.0,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 1.0,\n",
       "  'support': 10},\n",
       " 'weighted avg': {'precision': 1.0,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 1.0,\n",
       "  'support': 10}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_precision 1.0\n",
      "0_recall 1.0\n",
      "0_f1-score 1.0\n",
      "0_support 1.0\n",
      "1_precision 1.0\n",
      "1_recall 1.0\n",
      "1_f1-score 1.0\n",
      "1_support 1.0\n",
      "2_precision 1.0\n",
      "2_recall 1.0\n",
      "2_f1-score 1.0\n",
      "2_support 1.0\n",
      "3_precision 1.0\n",
      "3_recall 1.0\n",
      "3_f1-score 1.0\n",
      "3_support 1.0\n",
      "4_precision 1.0\n",
      "4_recall 1.0\n",
      "4_f1-score 1.0\n",
      "4_support 1.0\n",
      "5_precision 1.0\n",
      "5_recall 1.0\n",
      "5_f1-score 1.0\n",
      "5_support 1.0\n",
      "6_precision 1.0\n",
      "6_recall 1.0\n",
      "6_f1-score 1.0\n",
      "6_support 1.0\n",
      "7_precision 1.0\n",
      "7_recall 1.0\n",
      "7_f1-score 1.0\n",
      "7_support 1.0\n",
      "8_precision 1.0\n",
      "8_recall 1.0\n",
      "8_f1-score 1.0\n",
      "8_support 1.0\n",
      "9_precision 1.0\n",
      "9_recall 1.0\n",
      "9_f1-score 1.0\n",
      "9_support 1.0\n",
      "accuracy_total 1.0\n",
      "macro avg_precision 1.0\n",
      "macro avg_recall 1.0\n",
      "macro avg_f1-score 1.0\n",
      "macro avg_support 10.0\n",
      "weighted avg_precision 1.0\n",
      "weighted avg_recall 1.0\n",
      "weighted avg_f1-score 1.0\n",
      "weighted avg_support 10.0\n"
     ]
    }
   ],
   "source": [
    "for i in report.keys():\n",
    "    sub_dict = report[i]\n",
    "    if type(sub_dict) == dict:\n",
    "        for j in sub_dict.keys():\n",
    "            print(f\"{i}_{j} {float(sub_dict[j])}\")\n",
    "    else:\n",
    "        print(f\"{i}_total {float(sub_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48ee92e2d635797d39926e7d6499d96ee5185a55fde71480dcc71f65021be2ab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('eegeyenet_benchmark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
