{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import call\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>457</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>966</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3261</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3278</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3288</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3303</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3363</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id item_id  rating\n",
       "0       61       1       3\n",
       "1      120       1       2\n",
       "2      457       1       2\n",
       "3      670       1       3\n",
       "4      966       1       5\n",
       "..     ...     ...     ...\n",
       "95    3261       2       5\n",
       "96    3278       2       4\n",
       "97    3288       2       1\n",
       "98    3303       2       5\n",
       "99    3363       2       5\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df_full = pd.read_csv('/home/dustin/Documents/Study/Master2/CILProject22/data_raw/data_train.csv')\n",
    "df_train = pd.read_csv('/home/dustin/Documents/Study/Master2/CILProject22/data_raw/cross_validation/train_split_4.csv')\n",
    "df_test = pd.read_csv('/home/dustin/Documents/Study/Master2/CILProject22/data_raw/cross_validation/test_split_4.csv')\n",
    "\n",
    "dic_full = {\n",
    "    'user_id': [str(x).partition(\"_\")[0][1:] for x in df_full['Id']],\n",
    "    'item_id': [str(x).partition(\"_\")[2][1:] for x in df_full['Id']],\n",
    "    #'combined': [(str(x).partition(\"_\")[0][1:],str(x).partition(\"_\")[2][1:]) for x in df['Id']],\n",
    "    'rating': df_full['Prediction'],\n",
    "}\n",
    "dic_train = {\n",
    "    'user_id': [str(x).partition(\"_\")[0][1:] for x in df_train['Id']],\n",
    "    'item_id': [str(x).partition(\"_\")[2][1:] for x in df_train['Id']],\n",
    "    'rating': df_train['Prediction'],\n",
    "}\n",
    "dic_test = {\n",
    "    'user_id': [str(x).partition(\"_\")[0][1:] for x in df_test['Id']],\n",
    "    'item_id': [str(x).partition(\"_\")[2][1:] for x in df_test['Id']],\n",
    "    'rating': df_test['Prediction'],\n",
    "}\n",
    "\n",
    "full_data = pd.DataFrame(dic_full)\n",
    "train_data = pd.DataFrame(dic_train)\n",
    "test_data = pd.DataFrame(dic_test)\n",
    "test_data[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 5. 0. 4. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 5. 0. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 5. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 3.]\n",
      " [0. 0. 0. 1. 0. 5. 0. 5. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "n_users = 10000\n",
    "n_items = 1000\n",
    "train = np.zeros((n_users, n_items))\n",
    "test = np.zeros((n_users, n_items))\n",
    "\n",
    "# Create train and test sets via Tobi\n",
    "for row in train_data.itertuples(index = False):\n",
    "    train[int(row.user_id) - 1, int(row.item_id) - 1] = int(row.rating)\n",
    "\n",
    "for row in test_data.itertuples(index = False):\n",
    "    test[int(row.user_id) - 1, int(row.item_id) - 1] = int(row.rating)\n",
    "\n",
    "# Create train and test sets randomly\n",
    "def create_random_train_test(ratings):\n",
    "    \"\"\"\n",
    "    split into training and test sets,\n",
    "    remove 10 ratings from each user\n",
    "    and assign them to the test set\n",
    "    \"\"\"\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_index = np.random.choice(\n",
    "            np.flatnonzero(ratings[user]), size = 10, replace = True)\n",
    "\n",
    "        train[user, test_index] = 0.0\n",
    "        test[user, test_index] = ratings[user, test_index]\n",
    "        \n",
    "    # assert that training and testing set are truly disjoint\n",
    "    assert np.all(train * test == 0)\n",
    "    return train, test\n",
    "    \n",
    "\n",
    "# train, test = create_random_train_test(ratings)\n",
    "# del ratings\n",
    "\n",
    "print(train[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(10000, 1000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 2. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# normalization per item\n",
    "train_T = np.transpose(train)\n",
    "test_T = np.transpose(test)\n",
    "print(train_T.shape)\n",
    "avgs, stds = [], []\n",
    "for item in range(n_items):\n",
    "    mask = np.nonzero(train_T[item])\n",
    "    #mask_test = np.nonzero(test_T[item])\n",
    "    avg = np.mean(train_T[item][mask])\n",
    "    std = np.std(train_T[item][mask])\n",
    "    avgs.append(avg)\n",
    "    stds.append(std)\n",
    "    train_T[item][mask] = train_T[item][mask] - avg / std\n",
    "    #test_T[item][mask_test] = test_T[item][mask_test] - avg / std\n",
    "\n",
    "\n",
    "train = np.transpose(train_T)\n",
    "test = np.transpose(test_T)\n",
    "print(train.shape)\n",
    "print(test[:10][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo:\n",
    "# - change n_iter to some stop condition (often converges after 10 iterations)\n",
    "\n",
    "class ExplicitMF:\n",
    "    \"\"\"\n",
    "    Train a matrix factorization model using Alternating Least Squares\n",
    "    to predict empty entries in a matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_iters : int\n",
    "        number of iterations to train the algorithm\n",
    "        \n",
    "    n_factors : int\n",
    "        number of latent factors to use in matrix \n",
    "        factorization model, some machine-learning libraries\n",
    "        denote this as rank\n",
    "        \n",
    "    reg : float\n",
    "        regularization term for item/user latent factors,\n",
    "        since lambda is a keyword in python we use reg instead\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_iters, n_factors, reg):\n",
    "        self.reg = reg\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors  \n",
    "        self.n_user, self.n_item = train.shape\n",
    "        self.user_factors = np.random.random((self.n_user, self.n_factors))\n",
    "        self.item_factors = np.random.random((self.n_item, self.n_factors))\n",
    "        \n",
    "        \n",
    "    def fit(self, train, test):\n",
    "        \"\"\"\n",
    "        pass in training and testing at the same time to record\n",
    "        model convergence, assuming both dataset is in the form\n",
    "        of User x Item matrix with cells as ratings\n",
    "        \"\"\"\n",
    "\n",
    "        self.test_rmse_record  = []\n",
    "        self.train_rmse_record = []   \n",
    "        for _ in range(self.n_iters):\n",
    "            self.user_factors = self._als_step(train, self.user_factors, self.item_factors)\n",
    "            self.item_factors = self._als_step(train.T, self.item_factors, self.user_factors)\n",
    "            predictions = self.predict()\n",
    "            test_rmse = self.compute_rmse(test, predictions)\n",
    "            train_rmse = self.compute_rmse(train, predictions)\n",
    "            self.test_rmse_record.append(test_rmse)\n",
    "            self.train_rmse_record.append(train_rmse)\n",
    "        \n",
    "        return self    \n",
    "    \n",
    "    def _als_step(self, ratings, solve_vecs, fixed_vecs):\n",
    "        \"\"\"\n",
    "        when updating the user matrix,\n",
    "        the item matrix is the fixed vector and vice versa\n",
    "        \"\"\"\n",
    "        A = fixed_vecs.T.dot(fixed_vecs) + np.eye(self.n_factors) * self.reg\n",
    "        b = ratings.dot(fixed_vecs)\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        solve_vecs = b.dot(A_inv)\n",
    "        return solve_vecs\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"predict ratings for every user and item\"\"\"\n",
    "        pred = self.user_factors.dot(self.item_factors.T)\n",
    "        return pred\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_rmse(y_true, y_pred):\n",
    "        \"\"\"ignore zero terms prior to comparing the mse\"\"\"\n",
    "        mask = np.nonzero(y_true)\n",
    "        mse = mean_squared_error(y_true[mask], y_pred[mask])\n",
    "        return math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ExplicitMF at 0x7fe23fc5c400>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ExplicitMF(n_iters = 50, n_factors = 10, reg = .10)\n",
    "\n",
    "model.fit(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.019889825420967\n",
      "\n",
      " [[3.35755022 3.51721261 3.44835208 ... 3.20554749 3.34785839 3.66994406]\n",
      " [3.35629181 3.50820292 3.46304968 ... 3.22317655 3.34363682 3.64951072]\n",
      " [3.3480242  3.50945019 3.45117381 ... 3.18928639 3.326243   3.61431565]\n",
      " ...\n",
      " [3.356552   3.51643673 3.4382637  ... 3.19712123 3.34064867 3.68857261]\n",
      " [3.34023736 3.50071495 3.41926294 ... 3.20418481 3.32930313 3.72256877]\n",
      " [3.37598691 3.52764566 3.47093533 ... 3.23919523 3.36585445 3.69036787]]\n"
     ]
    }
   ],
   "source": [
    "# print(model.test_mse_record)\n",
    "pred = model.predict()\n",
    "pred_T = np.transpose(pred)\n",
    "for item in range(n_items):\n",
    "    pred_T[item] = pred_T[item] * stds[item] + avgs[item]\n",
    "\n",
    "pred = np.transpose(pred_T)\n",
    "\n",
    "print(f'RMSE: {model.compute_rmse(test, pred)}')\n",
    "# print(model.train_rmse_record, '\\n')\n",
    "print('\\n', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "# normalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('web3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2522a7ac3b60f852504f7e2e80aa0b42867087115d2f979bf28cdf9a03dea8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
