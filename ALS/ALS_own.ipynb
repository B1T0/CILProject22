{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2706</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2820</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2883</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2939</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2942</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  rating\n",
       "0        44        1     4.0\n",
       "1        61        1     3.0\n",
       "2        67        1     4.0\n",
       "3        72        1     3.0\n",
       "4        86        1     5.0\n",
       "..      ...      ...     ...\n",
       "95     2706        1     4.0\n",
       "96     2820        1     3.0\n",
       "97     2883        1     2.0\n",
       "98     2939        1     3.0\n",
       "99     2942        1     4.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df_full = pd.read_csv('../data_raw/data_train.csv')\n",
    "df_train = pd.read_csv('../data_raw/cross_validation/train_split_4.csv')\n",
    "df_test = pd.read_csv('../data_raw/cross_validation/test_split_4.csv')\n",
    "\n",
    "dic_full = {\n",
    "    'user_id': [int(str(x).partition(\"_\")[0][1:]) for x in df_full['Id']],\n",
    "    'item_id': [int(str(x).partition(\"_\")[2][1:]) for x in df_full['Id']],\n",
    "    #'combined': [(str(x).partition(\"_\")[0][1:],str(x).partition(\"_\")[2][1:]) for x in df['Id']],\n",
    "    'rating': [float(x) for x in df_full['Prediction']],\n",
    "}\n",
    "dic_train = {\n",
    "    'user_id': [int(str(x).partition(\"_\")[0][1:]) for x in df_train['Id']],\n",
    "    'item_id': [int(str(x).partition(\"_\")[2][1:]) for x in df_train['Id']],\n",
    "    'rating': [float(x) for x in df_train['Prediction']],\n",
    "}\n",
    "dic_test = {\n",
    "    'user_id': [int(str(x).partition(\"_\")[0][1:]) for x in df_test['Id']],\n",
    "    'item_id': [int(str(x).partition(\"_\")[2][1:]) for x in df_test['Id']],\n",
    "    'rating': [float(x) for x in df_test['Prediction']],\n",
    "}\n",
    "\n",
    "full_data = pd.DataFrame(dic_full)\n",
    "train_data = pd.DataFrame(dic_train)\n",
    "test_data = pd.DataFrame(dic_test)\n",
    "full_data[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 5.]\n",
      " [0. 0. 0. 3. 0. 5. 0. 4. 0. 0.]\n",
      " [0. 0. 0. 2. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 5. 0. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 5. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 5. 0. 0. 0. 3.]\n",
      " [0. 0. 0. 1. 0. 5. 0. 5. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "n_users = 10000\n",
    "n_items = 1000\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "train = np.zeros((n_users, n_items))\n",
    "test = np.zeros((n_users, n_items))\n",
    "\n",
    "# Create train and test sets via Tobi\n",
    "for row in full_data.itertuples(index = False):\n",
    "    ratings[int(row.user_id) - 1, int(row.item_id) - 1] = int(row.rating)\n",
    "\n",
    "for row in train_data.itertuples(index = False):\n",
    "    train[int(row.user_id) - 1, int(row.item_id) - 1] = int(row.rating)\n",
    "\n",
    "for row in test_data.itertuples(index = False):\n",
    "    test[int(row.user_id) - 1, int(row.item_id) - 1] = int(row.rating)\n",
    "\n",
    "\n",
    "print(ratings[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(10000, 1000)\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  2.34660803 -0.08553854\n",
      "  -0.45348009]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# normalization per item\n",
    "train_T = np.transpose(train)\n",
    "test_T = np.transpose(test)\n",
    "print(train_T.shape)\n",
    "avgs, stds = [], []\n",
    "for item in range(n_items):\n",
    "    mask = np.nonzero(train_T[item])\n",
    "    mask_test = np.nonzero(test_T[item])\n",
    "    avg = np.mean(train_T[item][mask])\n",
    "    std = np.std(train_T[item][mask])\n",
    "    avgs.append(avg)\n",
    "    stds.append(std)\n",
    "    train_T[item][mask] = (train_T[item][mask] - avg) / std\n",
    "    test_T[item][mask_test] = (test_T[item][mask_test] - avg) / std\n",
    "\n",
    "\n",
    "train = np.transpose(train_T)\n",
    "test_norm = np.transpose(test_T)\n",
    "print(train.shape)\n",
    "print(train[:10][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo:\n",
    "# - change n_iter to some stop condition (often converges after 10 iterations)\n",
    "\n",
    "class ExplicitMF:\n",
    "    \"\"\"\n",
    "    Training the ALS model, while updating the user and item factors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_iters, n_factors, reg):\n",
    "        self.reg = reg\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors  \n",
    "        self.n_user, self.n_item = train.shape\n",
    "        self.user_factors = np.random.random((self.n_user, self.n_factors))\n",
    "        self.item_factors = np.random.random((self.n_item, self.n_factors))\n",
    "        \n",
    "        \n",
    "    def fit(self, train, test):\n",
    "        \"\"\"\n",
    "        train the model. Doing ALS steps\n",
    "        \"\"\"\n",
    "\n",
    "        self.test_rmse_record  = []\n",
    "        self.train_rmse_record = []   \n",
    "        for i in range(self.n_iters):\n",
    "            print('iteration: ', i)\n",
    "            self.user_factors = self._als_step(train, self.user_factors, self.item_factors)\n",
    "            self.item_factors = self._als_step(train.T, self.item_factors, self.user_factors)\n",
    "            predictions = self.predict()\n",
    "            test_rmse = self.compute_rmse(test, predictions)\n",
    "            train_rmse = self.compute_rmse(train, predictions)\n",
    "            self.test_rmse_record.append(test_rmse)\n",
    "            self.train_rmse_record.append(train_rmse)\n",
    "        \n",
    "        return self    \n",
    "    \n",
    "    def _als_step(self, ratings, solve_vecs, fixed_vecs):\n",
    "        \"\"\"\n",
    "        Doing an ALS step as seen in the lecutre.\n",
    "        \"\"\"\n",
    "        for i in range(solve_vecs.shape[0]):\n",
    "            A = np.zeros((self.n_factors, self.n_factors))\n",
    "            b = np.zeros((self.n_factors,))\n",
    "            for j in range(fixed_vecs.shape[0]):\n",
    "                if ratings[i, j] != 0:\n",
    "                    A += np.outer(fixed_vecs[j], fixed_vecs[j])\n",
    "                    b += ratings[i][j] * fixed_vecs[j]\n",
    "            A += self.reg * np.eye(self.n_factors)\n",
    "            solve_vecs[i] = np.linalg.solve(A, b).T\n",
    "        \n",
    "        return solve_vecs\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"predict ratings for every user and item\"\"\"\n",
    "        pred = self.user_factors.dot(self.item_factors.T)\n",
    "        return pred\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_rmse(y_true, y_pred):\n",
    "        \"\"\"ignore zero terms prior to comparing the mse\"\"\"\n",
    "        mask = np.nonzero(y_true)\n",
    "        mse = mean_squared_error(y_true[mask], y_pred[mask])\n",
    "        return math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "iteration:  1\n",
      "iteration:  2\n",
      "iteration:  3\n",
      "iteration:  4\n",
      "iteration:  5\n",
      "iteration:  6\n",
      "iteration:  7\n",
      "iteration:  8\n",
      "iteration:  9\n",
      "iteration:  10\n",
      "iteration:  11\n",
      "iteration:  12\n",
      "iteration:  13\n",
      "iteration:  14\n",
      "iteration:  15\n",
      "iteration:  16\n",
      "iteration:  17\n",
      "iteration:  18\n",
      "iteration:  19\n",
      "[0.8941612767307773, 0.8009665240994799, 0.7758816958385989, 0.7615298830541224, 0.7527317955480755, 0.7469116032890195, 0.7427886653157787, 0.7397125919546231, 0.7373249917787268, 0.7354123062687097, 0.7338403288975182, 0.7325207645598608, 0.7313930647951241, 0.7304142768255687, 0.7295531334444967, 0.7287865221450797, 0.7280973215898928, 0.7274729545281443, 0.7269042685680689, 0.7263845849806015]\n"
     ]
    }
   ],
   "source": [
    "model = ExplicitMF(n_iters = 20, n_factors = 30, reg = 5.0)\n",
    "model.fit(train, test_norm)\n",
    "print(model.train_rmse_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.test_mse_record)\n",
    "pred = model.predict()\n",
    "pred_T = np.transpose(pred)\n",
    "for item in range(n_items):\n",
    "    pred_T[item] = pred_T[item] * stds[item] + avgs[item]\n",
    "    for i in range(len(pred_T[item])):\n",
    "        if pred_T[item][i] < 1:\n",
    "            pred_T[item][i] = 1\n",
    "        elif pred_T[item][i] > 5:\n",
    "            pred_T[item][i] = 5\n",
    "\n",
    "pred = np.transpose(pred_T)\n",
    "\n",
    "print(f'RMSE: {model.compute_rmse(test, pred)}')\n",
    "print('\\n', pred[:10][:10])\n",
    "print('\\n', train[:10][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Cross Validation\n",
    "regs = [0.5, 0.1, 0.05]\n",
    "n_factors = [25, 30, 35]\n",
    "\n",
    "best = (0, 0)\n",
    "best_rmse = 100\n",
    "for reg in regs:\n",
    "    for n_factor in n_factors:\n",
    "        model = ExplicitMF(n_iters = 100, n_factors = n_factor, reg = reg)\n",
    "        model.fit(train, test)\n",
    "        pred = model.predict()\n",
    "        pred_T = np.transpose(pred)\n",
    "        for item in range(n_items):\n",
    "            pred_T[item] = pred_T[item] * stds[item] + avgs[item]\n",
    "        pred = np.transpose(pred_T)\n",
    "        rmse = model.compute_rmse(test, pred)\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best = (reg, n_factor)\n",
    "            print(f'New best Hyperparameters: {best} with RMSE: {best_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.36702062 3.50447268 3.49662615 ... 3.22360299 3.33021409 3.68486082]\n",
      " [3.36264126 3.50196089 3.48604375 ... 3.37077123 3.39492532 3.70106834]\n",
      " [3.36657948 3.50439185 3.5122743  ... 3.26365413 3.38339937 3.64334944]\n",
      " ...\n",
      " [3.38493845 3.49272399 3.4756898  ... 3.22355556 3.3733448  3.73381173]\n",
      " [3.40735796 3.53016222 3.49874185 ... 3.21514371 3.33079054 3.77398583]\n",
      " [3.37612169 3.53682238 3.52696103 ... 3.31148591 3.34532214 3.74647044]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r37_c1</td>\n",
       "      <td>3.413237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r73_c1</td>\n",
       "      <td>3.366761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r156_c1</td>\n",
       "      <td>3.533388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r160_c1</td>\n",
       "      <td>3.442889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r248_c1</td>\n",
       "      <td>3.432730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176947</th>\n",
       "      <td>r9974_c1000</td>\n",
       "      <td>3.681848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176948</th>\n",
       "      <td>r9977_c1000</td>\n",
       "      <td>3.707133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176949</th>\n",
       "      <td>r9978_c1000</td>\n",
       "      <td>3.602696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176950</th>\n",
       "      <td>r9982_c1000</td>\n",
       "      <td>3.570269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176951</th>\n",
       "      <td>r9996_c1000</td>\n",
       "      <td>3.786906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176952 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  Prediction\n",
       "0             r37_c1    3.413237\n",
       "1             r73_c1    3.366761\n",
       "2            r156_c1    3.533388\n",
       "3            r160_c1    3.442889\n",
       "4            r248_c1    3.432730\n",
       "...              ...         ...\n",
       "1176947  r9974_c1000    3.681848\n",
       "1176948  r9977_c1000    3.707133\n",
       "1176949  r9978_c1000    3.602696\n",
       "1176950  r9982_c1000    3.570269\n",
       "1176951  r9996_c1000    3.786906\n",
       "\n",
       "[1176952 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize training data\n",
    "ratings_T = np.transpose(ratings)\n",
    "avgs_full, stds_full = [], []\n",
    "for item in range(n_items):\n",
    "    mask = np.nonzero(ratings_T[item])\n",
    "    avg = np.mean(ratings_T[item][mask])\n",
    "    std = np.std(ratings_T[item][mask])\n",
    "    avgs_full.append(avg)\n",
    "    stds_full.append(std)\n",
    "    ratings_T[item][mask] = ratings_T[item][mask] - avg / std\n",
    "\n",
    "ratings = np.transpose(ratings_T)\n",
    "\n",
    "# train the model\n",
    "print('\\n', 'Training the model...')\n",
    "model = ExplicitMF(n_iters = 200, n_factors = 30, reg = 0.1)\n",
    "model.fit(ratings, test)\n",
    "\n",
    "# predict ratings\n",
    "pred = model.predict()\n",
    "pred_T = np.transpose(pred)\n",
    "for item in range(n_items):\n",
    "    pred_T[item] = pred_T[item] * stds_full[item] + avgs_full[item]\n",
    "pred = np.transpose(pred_T)\n",
    "print(pred)\n",
    "\n",
    "# write to submission-file\n",
    "sample_sub = pd.read_csv(\"../data_raw/sampleSubmission.csv\")\n",
    "prediction = []\n",
    "for cell_id in sample_sub.Id:\n",
    "    row, col = cell_id.split(\"_\")\n",
    "    prediction.append(pred[int(row[1:])-1, int(col[1:])-1])\n",
    "sample_sub.Prediction = prediction\n",
    "sample_sub.to_csv(\"../data/als.csv\", index=False)\n",
    "sample_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "\n",
    "def tune_ALS(train_data, validation_data, maxIter, regParams, ranks):\n",
    "    \"\"\"\n",
    "    grid search function to select the best model based on RMSE of\n",
    "    validation data\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    validation_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    maxIter: int, max number of learning iterations\n",
    "    \n",
    "    regParams: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    ranks: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The best fitted ALS model with lowest RMSE score on validation data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in regParams:\n",
    "            # get ALS model\n",
    "            als = ALS().setMaxIter(maxIter).setRank(rank).setRegParam(reg)\n",
    "            # train ALS model\n",
    "            print(f'Training model with rank {rank} and regularization {reg}')\n",
    "            model = als.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"rating\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors and regularization = {}: '\n",
    "                  'validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and '\n",
    "          'regularization = {} with RSME = {}'.format(best_rank, best_regularization, min_error))\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def make_recommendations(self, fav_movie, n_recommendations):\n",
    "    \"\"\"\n",
    "    make top n movie recommendations\n",
    "    Parameters\n",
    "    ----------\n",
    "    fav_movie: str, name of user input movie\n",
    "    n_recommendations: int, top n recommendations\n",
    "    \"\"\"\n",
    "    # get data\n",
    "    movie_user_mat_sparse, hashmap = self._prep_data()\n",
    "    # get recommendations\n",
    "    raw_recommends = self._inference(\n",
    "        self.model, movie_user_mat_sparse, hashmap,\n",
    "        fav_movie, n_recommendations)\n",
    "    # print results\n",
    "    reverse_hashmap = {v: k for k, v in hashmap.items()}\n",
    "    print('Recommendations for {}:'.format(fav_movie))\n",
    "    for i, (idx, dist) in enumerate(raw_recommends):\n",
    "        print('{0}: {1}, with distance '\n",
    "              'of {2}'.format(i+1, reverse_hashmap[idx], dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lib = list(zip(train_data.user_id, train_data.item_id, train_data.rating))\n",
    "test_lib = list(zip(test_data.user_id, test_data.item_id, test_data.rating))\n",
    "full_lib = train_lib + test_lib\n",
    "\n",
    "df_full = spark.createDataFrame(full_lib, [\"user\", \"item\", \"rating\"])\n",
    "df = spark.createDataFrame([(0, 0, 4.0), (0, 1, 2.0), (1, 1, 3.0), (1, 2, 4.0), (2, 1, 1.0), (2, 2, 5.0)], [\"user\", \"item\", \"rating\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for manual testing\n",
    "als = ALS().setMaxIter(15).setRank(30).setRegParam(0.1)\n",
    "# train ALS model\n",
    "model = als.fit(df_train)\n",
    "# evaluate the model by computing the RMSE on the validation data\n",
    "\n",
    "predictions = model.transform(df_test)\n",
    "print(predictions.show())\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print('RMSE on test data = {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tune_ALS(df_train, df_test, maxIter = 12, regParams = [0.05, 0.1, 0.2], ranks = [10, 12])\n",
    "print('Training complete')\n",
    "pred = model.transform(df_test)\n",
    "\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"rating\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(pred)\n",
    "print('RSME: {}' .format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/5\n",
      "22/07/22 19:00:44 WARN TaskSetManager: Stage 1503 contains a task of very large size (19247 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1503:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:00:48 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 1503 (TID 3752): Attempting to kill Python Worker\n",
      "22/07/22 19:00:48 WARN TaskSetManager: Stage 1504 contains a task of very large size (19247 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:01:14 WARN TaskSetManager: Stage 1577 contains a task of very large size (8901 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user  item  prediction\n",
      "500501    37     1    3.208503\n",
      "789489    73     1    3.000793\n",
      "822574   156     1    3.679502\n",
      "Training model 2/5\n",
      "22/07/22 19:01:21 WARN TaskSetManager: Stage 1620 contains a task of very large size (19247 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1620:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:01:25 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 1620 (TID 4120): Attempting to kill Python Worker\n",
      "22/07/22 19:01:25 WARN TaskSetManager: Stage 1621 contains a task of very large size (19247 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:01:51 WARN TaskSetManager: Stage 1694 contains a task of very large size (8901 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user  item  prediction\n",
      "500501    37     1    3.228759\n",
      "789489    73     1    2.980950\n",
      "822574   156     1    3.667770\n",
      "Training model 3/5\n",
      "22/07/22 19:01:58 WARN TaskSetManager: Stage 1737 contains a task of very large size (19247 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1737:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:02:02 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 1737 (TID 4488): Attempting to kill Python Worker\n",
      "22/07/22 19:02:02 WARN TaskSetManager: Stage 1738 contains a task of very large size (19247 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:02:28 WARN TaskSetManager: Stage 1811 contains a task of very large size (8901 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user  item  prediction\n",
      "500501    37     1    3.224522\n",
      "789489    73     1    2.964534\n",
      "822574   156     1    3.662883\n",
      "Training model 4/5\n",
      "22/07/22 19:02:34 WARN TaskSetManager: Stage 1854 contains a task of very large size (19247 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1854:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:02:38 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 1854 (TID 4856): Attempting to kill Python Worker\n",
      "22/07/22 19:02:38 WARN TaskSetManager: Stage 1855 contains a task of very large size (19247 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:03:04 WARN TaskSetManager: Stage 1928 contains a task of very large size (8901 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user  item  prediction\n",
      "500501    37     1    3.208846\n",
      "789489    73     1    3.029075\n",
      "822574   156     1    3.647963\n",
      "Training model 5/5\n",
      "22/07/22 19:03:11 WARN TaskSetManager: Stage 1971 contains a task of very large size (19247 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1971:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:03:15 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 1971 (TID 5224): Attempting to kill Python Worker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:03:16 WARN TaskSetManager: Stage 1972 contains a task of very large size (19247 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/22 19:03:41 WARN TaskSetManager: Stage 2045 contains a task of very large size (8901 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user  item  prediction\n",
      "500501    37     1    3.165476\n",
      "789489    73     1    3.012002\n",
      "822574   156     1    3.676820\n",
      "         user  item  prediction\n",
      "500501     37     1    3.165476\n",
      "789489     73     1    3.012002\n",
      "822574    156     1    3.676820\n",
      "805715    160     1    3.271206\n",
      "1016742   248     1    3.242455\n",
      "22/07/22 19:03:48 WARN TaskSetManager: Stage 2120 contains a task of very large size (8901 KiB). The maximum recommended task size is 1000 KiB.\n",
      "+----+----+----------+\n",
      "|user|item|prediction|\n",
      "+----+----+----------+\n",
      "|  37|   1| 3.1654763|\n",
      "|  73|   1| 3.0120022|\n",
      "| 156|   1| 3.6768196|\n",
      "| 160|   1|  3.271206|\n",
      "| 248|   1| 3.2424545|\n",
      "| 256|   1| 3.3523054|\n",
      "| 284|   1| 3.0376537|\n",
      "| 400|   1| 3.0315964|\n",
      "| 416|   1| 3.5371642|\n",
      "| 456|   1| 3.2642639|\n",
      "| 474|   1| 2.5645995|\n",
      "| 495|   1| 3.1156893|\n",
      "| 515|   1| 1.7636681|\n",
      "| 518|   1| 3.4835413|\n",
      "| 521|   1| 3.9568653|\n",
      "| 559|   1| 2.7974775|\n",
      "| 596|   1| 3.1955385|\n",
      "| 614|   1| 3.4028368|\n",
      "| 621|   1| 2.9847357|\n",
      "| 661|   1| 3.1761184|\n",
      "+----+----+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r37_c1</td>\n",
       "      <td>3.207221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r73_c1</td>\n",
       "      <td>2.997471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r156_c1</td>\n",
       "      <td>3.666987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r160_c1</td>\n",
       "      <td>3.276756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r248_c1</td>\n",
       "      <td>3.231271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176947</th>\n",
       "      <td>r9974_c1000</td>\n",
       "      <td>3.383960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176948</th>\n",
       "      <td>r9977_c1000</td>\n",
       "      <td>3.483347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176949</th>\n",
       "      <td>r9978_c1000</td>\n",
       "      <td>2.910252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176950</th>\n",
       "      <td>r9982_c1000</td>\n",
       "      <td>3.124082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176951</th>\n",
       "      <td>r9996_c1000</td>\n",
       "      <td>3.677671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176952 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  Prediction\n",
       "0             r37_c1    3.207221\n",
       "1             r73_c1    2.997471\n",
       "2            r156_c1    3.666987\n",
       "3            r160_c1    3.276756\n",
       "4            r248_c1    3.231271\n",
       "...              ...         ...\n",
       "1176947  r9974_c1000    3.383960\n",
       "1176948  r9977_c1000    3.483347\n",
       "1176949  r9978_c1000    2.910252\n",
       "1176950  r9982_c1000    3.124082\n",
       "1176951  r9996_c1000    3.677671\n",
       "\n",
       "[1176952 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict ratings\n",
    "sample_sub = pd.read_csv(\"../data_raw/sampleSubmission.csv\")\n",
    "to_predict = []\n",
    "for i, cell_id in enumerate(sample_sub.Id):\n",
    "    row, col = cell_id.split(\"_\")\n",
    "    to_predict.append((int(row[1:]), int(col[1:])))\n",
    "df_sub = spark.createDataFrame(to_predict, [\"user\", \"item\"])\n",
    "\n",
    "ensemble = 5\n",
    "average = np.asarray([0.0] * len(to_predict))\n",
    "for i in range(ensemble):\n",
    "    als = ALS(seed=i).setMaxIter(15).setRank(30).setRegParam(0.1)\n",
    "    print(f'Training model {i+1}/{ensemble}')\n",
    "    model = als.fit(df_full)\n",
    "    predictions = model.transform(df_sub)\n",
    "    pandas_df = predictions.toPandas()\n",
    "    pandas_df = pandas_df.sort_values(by=['item', 'user'], ascending=True)\n",
    "    average += np.asarray(pandas_df['prediction'].values.tolist())\n",
    "    print(pandas_df[:3])\n",
    "average = average / ensemble\n",
    "\n",
    "print(pandas_df[:5])\n",
    "print(predictions.show())\n",
    "\n",
    "# write to csv\n",
    "sample_sub.Prediction = average\n",
    "sample_sub.to_csv(\"../data/als.csv\", index=False)\n",
    "sample_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r37_c1</td>\n",
       "      <td>3.173383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r73_c1</td>\n",
       "      <td>2.997006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r156_c1</td>\n",
       "      <td>3.646690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r160_c1</td>\n",
       "      <td>3.256994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r248_c1</td>\n",
       "      <td>3.261189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176947</th>\n",
       "      <td>r9974_c1000</td>\n",
       "      <td>3.395679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176948</th>\n",
       "      <td>r9977_c1000</td>\n",
       "      <td>3.484329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176949</th>\n",
       "      <td>r9978_c1000</td>\n",
       "      <td>2.893643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176950</th>\n",
       "      <td>r9982_c1000</td>\n",
       "      <td>3.079063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176951</th>\n",
       "      <td>r9996_c1000</td>\n",
       "      <td>3.659014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176952 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  Prediction\n",
       "0             r37_c1    3.173383\n",
       "1             r73_c1    2.997006\n",
       "2            r156_c1    3.646690\n",
       "3            r160_c1    3.256994\n",
       "4            r248_c1    3.261189\n",
       "...              ...         ...\n",
       "1176947  r9974_c1000    3.395679\n",
       "1176948  r9977_c1000    3.484329\n",
       "1176949  r9978_c1000    2.893643\n",
       "1176950  r9982_c1000    3.079063\n",
       "1176951  r9996_c1000    3.659014\n",
       "\n",
       "[1176952 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = predictions.toPandas()\n",
    "pandas_df = pandas_df.sort_values(by=['item', 'user'], ascending=True)\n",
    "print(pandas_df[:30])\n",
    "\n",
    "sample_sub.Prediction = pandas_df['prediction'].values.tolist()\n",
    "sample_sub.to_csv(\"../data/als.csv\", index=False)\n",
    "sample_sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('web3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2522a7ac3b60f852504f7e2e80aa0b42867087115d2f979bf28cdf9a03dea8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
